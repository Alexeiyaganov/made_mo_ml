{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEfPL00LH9E2"
   },
   "source": [
    "**Импортируем библиотеки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTVOodb9ukhD",
    "outputId": "9b4ef17d-debc-4f85-8421-a2b0131c2cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7B14-CphwSaC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy.stats import norm as norm_d\n",
    "from scipy.stats import randint\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.linalg import svdvals\n",
    "import scipy\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Optimizer\n",
    "import scipy.stats\n",
    "import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, DistilBertTokenizer,BertTokenizer,DistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMXkx6QBwpcC"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "if not pathlib.Path('./functions.py').is_file():\n",
    "  # !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/tests.py\n",
    "  !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/functions.py #alexrogozin12/opt_in_ml/blob/master/homework_5/functions.py\n",
    "  !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/datasets/a9a.txt\n",
    "  !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/datasets/a5a.txt\n",
    "from functions import *\n",
    "# from tests import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVKKAAdsJcm9"
   },
   "source": [
    "### Решаемая задача\n",
    "Для удобства продублируем здесь задачу, которую вы решали ещё в прошлом домашнем задании:\n",
    "\n",
    "$$ F(x) = f(x) + R(x) = \\frac{1}{m}\\sum\\limits_{i=1}^m\\underbrace{\\left(\\log\\left(1 + \\exp\\left(-y_i\\cdot (Ax)_i\\right)\\right) + \\frac{l_2}{2}\\|x\\|_2^2\\right)}_{f_i(x)} + \\underbrace{l_1\\|x\\|_1}_{R(x)} \\to \\min\\limits_{x\\in\\mathbb{R}^n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1CopnRWIQUj"
   },
   "source": [
    "предобработка данных, согласно прошлому заданию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "33gZlNon1F56"
   },
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    filename = dataset + \".txt\"\n",
    "\n",
    "    data = load_svmlight_file(filename)\n",
    "    A, y = data[0], data[1]\n",
    "    m, n = A.shape\n",
    "    \n",
    "    if (2 in y) & (1 in y):\n",
    "        y = 2 * y - 3\n",
    "    if (2 in y) & (4 in y):\n",
    "        y = y - 3\n",
    "    assert((-1 in y) & (1 in y))\n",
    "    \n",
    "    sparsity_A = A.count_nonzero() / (m * n)\n",
    "    return A, y, m, n, sparsity_A\n",
    "\n",
    "def compute_L(dataset, A):\n",
    "    filename = dataset+\"_L.txt\"\n",
    "    file_path = Path(filename)\n",
    "    if file_path.is_file():\n",
    "        with open(filename, 'rb') as file:\n",
    "            L, average_L, worst_L = pickle.load(file)\n",
    "    else:\n",
    "        sigmas = svds(A, return_singular_vectors=False)\n",
    "        m = A.shape[0]\n",
    "        L = sigmas.max()**2 / (4*m)\n",
    "        \n",
    "        worst_L = 0\n",
    "        average_L = 0\n",
    "        denseA = A.toarray()\n",
    "        for i in range(m):\n",
    "            L_temp = (norm(denseA[i])**2)*1.0 / 4\n",
    "            average_L += L_temp / m\n",
    "            if L_temp > worst_L:\n",
    "                worst_L = L_temp\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump([L, average_L, worst_L],file)\n",
    "    return L, average_L, worst_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TPmoJ6H3gvL",
    "outputId": "ae7ae8d0-3867-4645-eee6-febc9b5ea144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число функций в сумме:  32561 , размерность задачи:  123\n",
      "Константа гладкости всей функции:  1.5719196992226623\n",
      "Средняя константа гладкости     :  3.467276803535652\n",
      "Худшая константа гладкости      :  3.5\n",
      "Доля ненулевых элементов:  0.11275696922074716\n"
     ]
    }
   ],
   "source": [
    "dataset = \"a9a\"\n",
    "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
    "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
    "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "print(\"Константа гладкости всей функции: \", L)\n",
    "print(\"Средняя константа гладкости     : \", average_L)\n",
    "print(\"Худшая константа гладкости      : \", worst_L)\n",
    "print(\"Доля ненулевых элементов: \", sparsity_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4KPH6OW1PYB"
   },
   "source": [
    "## Задание №1 \n",
    "\n",
    "__*данное задание стоит 3 балла*__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptPsff6q6Df1"
   },
   "source": [
    "### Пункт №1\n",
    "\n",
    "__*данный пункт стоит 1 балл*__\n",
    "\n",
    "Реализуйте метод оптимизации Adam для логистической регрессии\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align}\n",
    "m_t &= \\beta_1 \\ m_{t-1} + (1 - \\beta_1)\\ g  \\\\ \n",
    "v_t &= \\beta_2 \\ v_{t-1} +  (1-\\beta_2)\\ g_{t}^2\\\\\n",
    "\\hat{m_t} &= \\frac{m_t}{1 - \\beta_1^t}\\\\\n",
    "\\hat{v_t} &= \\frac{v_t}{1 - \\beta_2^t}\\\\\n",
    "\\theta_t &= \\theta_{t-1} -  (\\frac{\\gamma}{\\sqrt{\\hat{v_t}} + \\delta}\\hat{m_t})\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "https://arxiv.org/pdf/1412.6980.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VHOlsSwx6Cfu"
   },
   "outputs": [],
   "source": [
    "# from functions import *\n",
    "def adam(filename, x_init, A, y, gamma, beta1, beta2, delta=1e-8, \n",
    "         l2=0, sparse_full=True, sparse_stoch=False, l1=0, S=50, max_t=np.inf,\n",
    "         batch_size=1, indices=None, save_info_period=100, x_star=None):\n",
    "    m, n = A.shape\n",
    "    assert(len(x_init) == n)\n",
    "    assert(len(y) == m)\n",
    "    if indices is None:\n",
    "        indices = randint.rvs(low=0, high=m, size=min(int(S*m*1.0/batch_size), int(100000/batch_size))*batch_size,random_state=42)\n",
    "    indices_size = len(indices)\n",
    "    if x_star is None:\n",
    "        x_star = np.zeros(n)\n",
    "    ref_point = np.array(x_star) #если знаем решение, то ref_point поможет вычислять расстояние до него\n",
    "    x = np.array(x_init)\n",
    "    mm = np.zeros(n)\n",
    "    v = np.zeros(n)\n",
    "    \n",
    "    #эти массивы мы будем сохранять в файл\n",
    "    its = np.array([0])\n",
    "    tim = np.array([0.0])\n",
    "    data_passes = np.array([0.0])\n",
    "    func_val = np.array([F(x, [A, y, l2, sparse_full, l1])])\n",
    "    sq_distances = np.array([norm(x - ref_point) ** 2])\n",
    "    \n",
    "    t_start = time.time()\n",
    "    num_of_data_passes = 0.0\n",
    "    \n",
    "    if sparse_stoch:\n",
    "        A_for_batch = A\n",
    "    else:\n",
    "        A_for_batch = A.toarray()\n",
    "    \n",
    "    indices_counter = 0\n",
    "    \n",
    "    #метод\n",
    "    print(int(S*m/batch_size))\n",
    "    for it in range(int(S*m/batch_size)):\n",
    "        if indices_counter == indices_size:\n",
    "            indices_counter = 0\n",
    "            indices = randint.rvs(low=0, high=m, size=indices_size)\n",
    "        batch_ind = indices[indices_counter:(indices_counter+batch_size)]\n",
    "        indices_counter += batch_size\n",
    "        #ваш код здесь\n",
    "        g = logreg_grad(x, [A_for_batch[indices], y[indices], l2, sparse_stoch])\n",
    "        mm = beta1 * mm + (1 - beta1) * g\n",
    "        v = beta2 * v + (1 - beta2) * g ** 2\n",
    "        m_hat = m / (1-beta1**(it+1))\n",
    "        v_hat = v / (1-beta2**(it+1))\n",
    "        x = x - gamma*m_hat/(v_hat + delta)\n",
    "\n",
    "        num_of_data_passes += batch_size/m\n",
    "        if ((it + 1) % save_info_period == 0):\n",
    "            its = np.append(its, it + 1)\n",
    "            tim = np.append(tim, time.time() - t_start)\n",
    "            data_passes = np.append(data_passes, num_of_data_passes)\n",
    "            func_val = np.append(func_val, F(x, [A, y, l2, sparse_full, l1]))\n",
    "            sq_distances = np.append(sq_distances, norm(x - ref_point) ** 2)\n",
    "        if tim[-1] > max_t:\n",
    "            break\n",
    "    \n",
    "    if ((it + 1) % save_info_period != 0):\n",
    "        its = np.append(its, it + 1)\n",
    "        tim = np.append(tim, time.time() - t_start)\n",
    "        data_passes = np.append(data_passes, num_of_data_passes)\n",
    "        func_val = np.append(func_val, F(x, [A, y, l2, sparse_full, l1]))\n",
    "        sq_distances = np.append(sq_distances, norm(x - ref_point) ** 2)\n",
    "    \n",
    "    #сохранение результатов в файл\n",
    "    res = {'last_iter':x, 'func_vals':func_val, 'iters':its, 'time':tim, 'data_passes':data_passes,\n",
    "           'squared_distances':sq_distances}\n",
    "    if not os.path.isdir('./dump'):\n",
    "      os.mkdir('./dump')\n",
    "    with open(\"dump/\"+filename+\"_Adam_gamma_\"+str(gamma)+\"_beta1_\"+str(beta1)+\"_beta2_\"+str(beta2)\n",
    "              +\"_l2_\"+str(l2)+\"_l1_\"+str(l1)+\"_num_of_epochs_\"+str(S)\n",
    "              +\"_batch_size_\"+str(batch_size)+\".txt\", 'wb') as file:\n",
    "        pickle.dump(res, file)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "pOwliBam5gMx",
    "outputId": "8d3413f1-3e6a-4c6c-cde7-718372ab8cb1"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-56589c010587>\u001b[0m in \u001b[0;36madam\u001b[0;34m(filename, x_init, A, y, gamma, beta1, beta2, delta, l2, sparse_full, sparse_stoch, l1, S, max_t, batch_size, indices, save_info_period, x_star)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mindices_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#ваш код здесь\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mA_for_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_stoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/functions.py\u001b[0m in \u001b[0;36mlogreg_grad\u001b[0;34m(x, args)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlogreg_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(10)\n",
    "x_init = np.ones(n)\n",
    "dataset = \"a9a\"\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "gamma_gd = 1.0/((L+l2))\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "gamma_schedule = [gamma, 10, 0.5]\n",
    "S = 10000\n",
    "beta1 = 0.9\n",
    "gamma_adam = 0.001\n",
    "gamma_adagrad = 1.0\n",
    "beta2 = 0.99\n",
    "indices = None\n",
    "\n",
    "res = adam(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma_adam,\n",
    "           beta1=beta1, beta2=beta2, l2=l2, \n",
    "           sparse_full=False, sparse_stoch=False, l1=l1, S=S, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rJHWmyF5zq4"
   },
   "source": [
    "Тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "RW4PuIDpBYRt",
    "outputId": "54a35a95-3200-4f08-a8b6-8e8930a7d634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-31 08:42:44--  https://raw.githubusercontent.com/pcgames/datasets/master/tests/Adam_test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13025933 (12M) [application/octet-stream]\n",
      "Saving to: ‘Adam_test.txt’\n",
      "\n",
      "Adam_test.txt       100%[===================>]  12.42M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-05-31 08:42:45 (118 MB/s) - ‘Adam_test.txt’ saved [13025933/13025933]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4f07bbdd866a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Adam_test.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtest_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'что-то не так...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "if not pathlib.Path('./Adam_test.txt').is_file():\n",
    "  !wget https://raw.githubusercontent.com/pcgames/datasets/master/tests/Adam_test.txt\n",
    "with open('./Adam_test.txt','rb') as f:\n",
    "  test_res=pickle.load(f)\n",
    "assert (abs(test_res['last_iter']-res['last_iter'])<1e-6).all(),'что-то не так...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9LECLs0i-eF"
   },
   "source": [
    "### Пункт №2\n",
    "\n",
    "__*данный пункт стоит 1 балл*__\n",
    "\n",
    "Сравните результаты данного экспермента с результатами, полученными в прошлом домашнем задании для методов  __SGD__, __SVRG__ и ускоренным методом Нестерова (метод __FISTA__ без prox_r):\n",
    "- Нарисуйте графики сходимости\n",
    "- Исходя из теории, полученной на лекции, обоснуйте результаты, полученные в эксперименте, а так же сделайте выводы о работе данных методов на поставленной задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5WI6ng3c5BAB"
   },
   "outputs": [],
   "source": [
    "from algorithms import *\n",
    "\n",
    "res_sgd = sgd_const_stepsize(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=False, sparse_stoch=False, \n",
    "     l1=l1, S=S, max_t=np.inf, batch_size=batch_size)\n",
    "\n",
    "res_svrg = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=False, sparse_stoch=False, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=None)\n",
    "\n",
    "res_fista = FISTA(filename=filename, x_init=x_init, A=A, y=y, L=L+l2, mu=l2, \n",
    "     sparse=False, l1=l1, S=S, max_t=np.inf)\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res['func_vals'], label='Adam')\n",
    "plt.plot(res_sgd['func_vals'], label='SGD')\n",
    "plt.plot(res_svrg['func_vals'], label='SVRG')\n",
    "\n",
    "plt.plot(res_fista['func_vals'], label='FISTA')\n",
    "plt.legend()\n",
    "\n",
    "# dataset = \"a9a\"\n",
    "# filename=dataset+\"_x_init_all_ones\"\n",
    "\n",
    "# methods = [\n",
    "#          ['Adam', [l2, l1, S], f', S ={S}, ', None]\n",
    "#          ['SGD', [l2, l1, S], f', S ={S}, ', None]\n",
    "#          ['SVRG', [l2, l1, S], f', S ={S}, ', None]\n",
    "#          ['FISTA', [l2, l1, S], f', S ={S}, ', None]\n",
    "# ]\n",
    "\n",
    "# mode_y = 'squared_distances'\n",
    "# mode_x = 'time'\n",
    "# figsize = (12, 8)\n",
    "# fontsize = 20\n",
    "# title = dataset+\", (m,n) = (\"+str(m)+\",\"+str(n)+\"), l2 = L/\"+str(int(L/l2))+\", l1 = L/\"+str(int(L/l1))\n",
    "\n",
    "# args_for_plots = [dataset, filename, mode_y, mode_x, figsize, fontsize, title, methods]\n",
    "# make_plots(args=args_for_plots)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMYsaZsnhqkt"
   },
   "source": [
    "### Пункт №3 \n",
    "\n",
    "__*данный пункт стоит 1 балл*__\n",
    "\n",
    "Проведите аналогичный эксперимент на другом датасете, сохраните результат и отправьте его вместе с домашним заданием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GviwusXrhTEs",
    "outputId": "10f51ad0-79dd-4c35-88c8-86856b24657b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число функций в сумме:  6414 , размерность задачи:  122\n",
      "Константа гладкости всей функции:  1.5740271677041653\n",
      "Средняя константа гладкости     :  3.466596507639382\n",
      "Худшая константа гладкости      :  3.5\n",
      "Доля ненулевых элементов:  0.11365890188982093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "dataset = \"a5a\"\n",
    "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
    "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
    "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "print(\"Константа гладкости всей функции: \", L)\n",
    "print(\"Средняя константа гладкости     : \", average_L)\n",
    "print(\"Худшая константа гладкости      : \", worst_L)\n",
    "print(\"Доля ненулевых элементов: \", sparsity_A)\n",
    "%%time\n",
    "np.random.seed(10)\n",
    "x_init = np.ones(n)\n",
    "dataset = \"a5a\"\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "gamma_gd = 1.0/((L+l2))\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "gamma_schedule = [gamma, 10, 0.5]\n",
    "S = 10000\n",
    "beta1 = 0.9\n",
    "gamma_adam = 0.001\n",
    "gamma_adagrad = 1.0\n",
    "beta2 = 0.99\n",
    "indices = None\n",
    "\n",
    "res = adam(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma_adam,\n",
    "           beta1=beta1, beta2=beta2, l2=l2, \n",
    "           sparse_full=False, sparse_stoch=False, l1=l1, S=S, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMw5aUP_1Zrg"
   },
   "source": [
    "## Задание №2\n",
    "\n",
    "__*данное задание стоит 4 балла*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTV5--U-GYre"
   },
   "source": [
    "### Пункт №1\n",
    "__*данный пункт стоит 2 балла*__\n",
    "\n",
    "реализовать метод оптимизации ACClip, о котором рассказывалось на лекции  \n",
    "$$\n",
    "\\large\n",
    "\\begin{align}\n",
    "for \\, k=&1\\cdots N- количество \\, эпох\\, прохода\\, по\\, данным\\\\\n",
    "&for \\, t=1\\cdots T- количество \\, частей\\, , на \\, которое \\,разделен \\, весь \\, датасет\\,рандомным\\,образом\\\\\n",
    "&\\,\\,\\,\\,\\,\\,\\,\\,m_t = \\beta_1 \\ m_{t-1} + (1 - \\beta_1)\\ g_t \\\\ \n",
    "&\\,\\,\\,\\,\\,\\,\\,\\, \\tau^\\alpha_t = \\beta_2 \\tau_{t-1}^\\alpha +  (1-\\beta_2)\\ g_{t}^\\alpha  \\\\\n",
    "&\\,\\,\\,\\,\\,\\,\\,\\,\\hat{g_t} = \\min\\{\\frac{\\tau_t}{|m_t|+\\epsilon},1\\}m_t \\\\\n",
    "%\\hat{v_t} = \\frac{v_t}{1 - \\beta^t}\\\\\n",
    "&\\,\\,\\,\\,\\,\\,\\,\\,\\theta_t = \\theta_{t-1} -  \\eta \\hat{g_t}\\\\\n",
    "& endfor\\\\\n",
    "endfor\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "https://arxiv.org/pdf/1912.03194.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "b3-5-6U-Bu2j"
   },
   "outputs": [],
   "source": [
    "class ACC(Optimizer):\n",
    "    def __init__(self, \n",
    "                 params, \n",
    "                 lr=1e-4, \n",
    "                 betas=(0.9, 0.99), \n",
    "                 eps=1e-5,\n",
    "                 w=1e-5,\n",
    "                 alpha=2):\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,weight_decay=w,alpha=2)\n",
    "        # тут вызываем конструктор базового класса и сохраняем параметры обучения\n",
    "        # их можно достать через self.param_groups\n",
    "        super(ACC, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self,closure=None):\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            # итерируемся по всем группам параметров нашей сети\n",
    "            # тут можно вытащить сохраненные параметры в группе\n",
    "            beta1, beta2 = group['betas'] \n",
    "            eps = group['eps']\n",
    "            w = group['weight_decay']\n",
    "            lr = group['lr']\n",
    "            alpha=group['alpha']\n",
    "\n",
    "            for p in group['params']:\n",
    "                # итерируемся по всем парамерам в данно группе\n",
    "                # если нет градиента по параметрам скипаем его\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                # забираем тензор градиента    \n",
    "                grad = p.grad.data\n",
    "                \n",
    "                # тут храняться значения, которые мы расчитываем в процессе \n",
    "                # по каждому параметру в группе нужно расчитывать свои значения\n",
    "                state = self.state[p]\n",
    "\n",
    "                # если параметры мы еще не записали инициализируем их значения\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    #начальное значение m\n",
    "                    state['momentum'] = torch.zeros_like(p.data)\n",
    "\n",
    "                    # начальное значение \\tau^{\\alpha}\n",
    "                    state['t'] = torch.zeros_like(p.data)\n",
    "\n",
    "\n",
    "                t, m = state['t'], state['momentum']\n",
    "                        \n",
    "                # запоминаем шаг\n",
    "                state['step'] += 1\n",
    "                # Считаем параметры.\n",
    "                # g = log\n",
    "                m = beta1 * m + (1 - beta1) * grad\n",
    "                t = torch.pow(beta2*torch.pow(t, alpha)+(1-beta2)*(grad.abs()**alpha), 1./alpha)\n",
    "                g_hat = (t/(m.abs()+eps)).clamp(min=0.0, max=1.0)*m\n",
    "                \n",
    "                # обновляем веса в p.data, \n",
    "                w = w - lr * g_hat\n",
    "\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlAvmWSdyoyX"
   },
   "source": [
    "Протестируем реализованный метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qexxOhQSj8Mu",
    "outputId": "8c26e158-0521-41dc-b1d8-afb4591c5765"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "if not pathlib.Path('./apples_pears.csv').is_file():\n",
    "  !wget https://raw.githubusercontent.com/pcgames/datasets/master/apples_pears.csv\n",
    "  !wget https://raw.githubusercontent.com/pcgames/datasets/master/tests/ACC_test.pt\n",
    "\n",
    "\n",
    "data=pd.read_csv('./apples_pears.csv')\n",
    "X = torch.FloatTensor(data.iloc[:,:2].values) # матрица объекты-признаки\n",
    "y = torch.LongTensor(data['target'].values.reshape((-1, 1))).view(-1)  # классы (столбец из нулей и единиц)\n",
    "\n",
    "torch.manual_seed(10)\n",
    "np.random.seed(10)\n",
    "NN=nn.Sequential(nn.Linear(X.shape[1],\n",
    "                                torch.unique(y).shape.numel()\n",
    "                                ),\n",
    "                       )\n",
    "loss_fn=torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "learning_rate = 0.01  \n",
    "optimizer = ACC(NN.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    y_pred=NN.forward(X)\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "testing_NN=nn.Sequential(nn.Linear(X.shape[1],\n",
    "                                torch.unique(y).shape.numel()\n",
    "                                ),\n",
    "                       )\n",
    "testing_NN.load_state_dict(torch.load('./ACC_test.pt'))\n",
    "a=testing_NN.parameters()\n",
    "\n",
    "for b in NN.parameters():\n",
    "  c=next(a).data.clone()\n",
    "  d=b.data.clone()\n",
    "  assert ((c-d).abs()<1e-6).values, 'что-то не так!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckwO8PMK9WqI"
   },
   "source": [
    "### Пункт №2\n",
    "__*в данном пункте описание каждого эксперимента стоит 1 балл*__\n",
    "\n",
    "Проведите эксперименты ,аналогичные проведенным на семинаре, с использованием алгоритма ACClip:\n",
    "- Получите распределение норм разностей стох. и полного градиентов для языковой модели bert на датасете CoLA\n",
    "\n",
    "- Получите распредиление норм разностей стох. и полного градиентов на модели VGG16 для датасета CIFAR10\n",
    "\n",
    "Сравните результаты, с результатами полученными для алгоритмов Adam SGD+momentum и обоснуйте результаты исходя из материалов, полученных на лекции №8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2yqdkzeQJnP"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj3--oa6QNCM"
   },
   "source": [
    "#### Предобработка данных\n",
    "\n",
    "Загрузим датасет из семинара и проведем его предобработку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5PPNtJRRzzZ",
    "outputId": "98b708c9-95fe-4a16-921b-d7d9893b03fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=753fe2536a0ac07952663fb57f53037cd559a187103616471882b99c40800941\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Downloading dataset\n",
      "Archive:  cola_public_1.1.zip\n",
      "   creating: cola_public/\n",
      "  inflating: cola_public/README      \n",
      "   creating: cola_public/tokenized/\n",
      "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
      "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
      "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
      "   creating: cola_public/raw/\n",
      "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
      "  inflating: cola_public/raw/in_domain_train.tsv  \n",
      "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
     ]
    }
   ],
   "source": [
    "# Unzip the dataset (if we haven't already)\n",
    "!pip install wget\n",
    "import wget\n",
    "import os\n",
    "print('Downloading dataset')\n",
    "# The URL for the dataset zip file.\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./cola_public_1.1.zip'):\n",
    "  wget.download(url, './cola_public_1.1.zip')\n",
    "  if not os.path.exists('./cola_public/'):\n",
    "    !unzip cola_public_1.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "xE9fibOyQecP",
    "outputId": "321ccd7b-66dd-4660-c719-e1168744d0b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our friends won't buy this analysis, let alone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization and I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization or I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The more we study verbs, the crazier they get.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Day by day the facts are getting murkier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8546</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Poseidon appears to own a dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8547</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Digitize is my happiest memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8548</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is easy to slay the Gorgon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I had the strangest feeling that I knew you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8550</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What all did you get for Christmas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8551 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  ...                                           sentence\n",
       "0               gj04  ...  Our friends won't buy this analysis, let alone...\n",
       "1               gj04  ...  One more pseudo generalization and I'm giving up.\n",
       "2               gj04  ...   One more pseudo generalization or I'm giving up.\n",
       "3               gj04  ...     The more we study verbs, the crazier they get.\n",
       "4               gj04  ...          Day by day the facts are getting murkier.\n",
       "...              ...  ...                                                ...\n",
       "8546            ad03  ...                   Poseidon appears to own a dragon\n",
       "8547            ad03  ...                     Digitize is my happiest memory\n",
       "8548            ad03  ...                     It is easy to slay the Gorgon.\n",
       "8549            ad03  ...       I had the strangest feeling that I knew you.\n",
       "8550            ad03  ...                What all did you get for Christmas?\n",
       "\n",
       "[8551 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t',\n",
    "                 header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaRCf8v3R90B"
   },
   "source": [
    "Поскольку в данной части задания мы будем использовать тот же самый [CoLA Dataset](https://nyu-mll.github.io/CoLA/#) и ту же самую [модель](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification), проведем аналогичную предобработку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSxGskXeRm-o"
   },
   "outputs": [],
   "source": [
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# токенизируем предложения исходного датасета\n",
    "input_ids = []\n",
    "# For every sentence...\n",
    "for sent in df.sentence.values:\n",
    "    #   (1) токинизируем предложение.\n",
    "    #   (2) добавляем символ `[CLS]`в начало предложения.\n",
    "    #   (3) и символ `[SEP]`в конец.\n",
    "    #   (4) маркеруем все токены в их id\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # добавляем '[CLS]' и '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "print('Original: ', df.sentence.values[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "MAX_LEN =  max([len(sen) for sen in input_ids])+1\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "print('\\Done.')\n",
    "# создадим attantion маску для кажого предложения\n",
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - если  ID =0 тогда не стоит обрабатывать данный токен в процессе обучения, поскольку это паддинг\n",
    "    #   -  если  ID >0 тогда стоит использовать данный токен, поскольку он является частью предложения\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    attention_masks.append(att_mask)\n",
    "\n",
    "\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,df.label.values, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, df.label.values,\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "### даталоадер для вычисления полного градиента\n",
    "batch_size = 250#train_inputs.shape[0]\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader_for_full_grad = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "### для обучения\n",
    "batch_size = 16#train_inputs.shape[0]\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0me_7jZXRm71"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(15)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "  \"bert-base-uncased\", # 12-ти слойная модель BERT с предобученными весами\n",
    "  num_labels = 2, # количество выходных хначений для бинарной классификации  \n",
    "  output_attentions = False, # true, если необходимо брать attention веса модели.\n",
    "  output_hidden_states = False, #true, если необходимо брать значения со скрытых слоёв.\n",
    ")\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59uq_rfFRm49"
   },
   "outputs": [],
   "source": [
    "optimizer = #воспользуйтесь Вашим оптимизатором\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dwp8L5eRm1p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq3yMSWg15_t"
   },
   "source": [
    "#### Эксперимент №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWTa8AK5P7hT"
   },
   "source": [
    "**Функции**\n",
    "\n",
    "воспользуемся функциями из семинарского ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOlwS_KUP6PL"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "def get_batch_grad(model):\n",
    "  gr=[]\n",
    "  for i in model.parameters():\n",
    "    if i.requires_grad:\n",
    "      gr.append(i.grad.view(-1))\n",
    "  return torch.cat(gr)\n",
    "def get_loss(batch,model):\n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_input_mask = batch[1].to(device)\n",
    "  b_labels = batch[2].to(device)\n",
    "  outputs = model(b_input_ids, \n",
    "                      token_type_ids=None, \n",
    "                      attention_mask=b_input_mask, \n",
    "                      labels=b_labels)\n",
    "\n",
    "  loss=outputs[0]\n",
    "  return loss\n",
    "def compute_full_grad(model):\n",
    "  fully_grad=[]\n",
    "  for step, batch in enumerate(train_dataloader_for_full_grad):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss=get_loss(batch,model)\n",
    "    loss.backward()\n",
    "\n",
    "    fully_grad = fully_grad + get_batch_grad(model) * \\\n",
    "        train_dataloader_for_full_grad.batch_size if fully_grad!=[] \\\n",
    "            else get_batch_grad(model) * train_dataloader_for_full_grad.batch_size\n",
    "\n",
    "  print(\"full grad computed\")\n",
    "  return fully_grad / (step * train_dataloader_for_full_grad.batch_size)\n",
    "def draw_norm_hist(norm_diffs):\n",
    "  bins_n=500\n",
    "  counts, bins=np.histogram(norm_diffs,bins_n)\n",
    "  mu = np.mean(norm_diffs)\n",
    "  sigma = np.sqrt(np.mean((norm_diffs - mu)**2))\n",
    "  temp2 = np.linspace(0, bins[-1], bins_n)\n",
    "  plt.semilogy(temp2, scipy.stats.norm.pdf(temp2, mu, sigma), linewidth=2, color='red', marker='d',\n",
    "            markersize = 15, \n",
    "            markevery=range(0, bins_n, 100))\n",
    "  plt.hist(bins[:-1], bins, weights=counts)\n",
    "  plt.yscale('log')\n",
    "  plt.show()\n",
    "\n",
    "def compute_norm_diffs(model):\n",
    "  full_grad=compute_full_grad(model)\n",
    "  mini_norms=[]\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    loss=get_loss(batch,model)\n",
    "    loss.backward()\n",
    "    mini_norms.append((get_batch_grad(model)-full_grad).norm().item())\n",
    "  print(\"norm diffs computed\")\n",
    "\n",
    "  return np.array(mini_norms)\n",
    "\n",
    "def training_and_drawing(model,n_epochs,optimizer):\n",
    "  norm_diffs_every_epoch=[]\n",
    "  for i in tqdm.tqdm(range(n_epochs)):\n",
    "    model.eval()\n",
    "    norm_diffs_every_epoch.append(compute_norm_diffs(model))\n",
    "    if i:\n",
    "      draw_norm_hist(norm_diffs_every_epoch[-1])\n",
    "    else:\n",
    "      draw_norm_hist(norm_diffs_every_epoch)\n",
    "    print(\"start_training\")\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "      optimizer.zero_grad()\n",
    "      loss=get_loss(batch,model)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  validation(model)\n",
    "  return norm_diffs_every_epoch\n",
    "\n",
    "def get_accuracy(model,batch):\n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_input_mask = batch[1].to(device)\n",
    "  b_labels = batch[2].to(device)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(b_input_ids, \n",
    "                      token_type_ids=None, \n",
    "                      attention_mask=b_input_mask, \n",
    "                      labels=b_labels)\n",
    "  # print(outputs.logits)\n",
    "  logits = outputs.logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "   \n",
    "\n",
    "  return flat_accuracy(logits, label_ids)\n",
    "def flat_accuracy(preds, labels):\n",
    "  # print(preds.shape())\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  labels_flat = labels.flatten()\n",
    "  return np.sum(pred_flat == labels_flat) / len(labels_flat),matthews_corrcoef(labels_flat, pred_flat)                \n",
    "def validation(model):\n",
    "  print(\"Running Validation...\")\n",
    "  matthews_set=[]\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    tmp_eval_accuracy,matthew = get_accuracy(model,batch)\n",
    "    matthews_set.append(matthew)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "\n",
    "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps) )\n",
    "  print(\" matthews_corrcoef_metric: {0:.2f}\".format(np.mean(matthews_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vazLf3eYfHwI"
   },
   "outputs": [],
   "source": [
    "norm_diffs_every_epoch_Adam=training_and_drawing(model,epochs,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-rctCPqqCKa"
   },
   "source": [
    "#### Эксперимент №2 \n",
    "Сделаем аналогичный эксперимент для изображений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "c698d5d07ae54f9cb44133cf476c670e",
      "c2cb84aa531a4ffd9767b33f19d04ace",
      "7f7266c8a5194d1f88f1cfa4edf776aa",
      "ea9e54a6bb52434b87fa49e393f90d52",
      "b39be4e467e44fdaa0c1071b63456d6f",
      "bc78da03b354499588de50590a0a67ac",
      "f61f2a1e22b242fe810e8c5788bc43a4",
      "b969d72ac9694d76bac133f84a077c28"
     ]
    },
    "id": "c-7DYgW8qSsG",
    "outputId": "33686c8d-8146-484c-bec0-7d70255451c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c698d5d07ae54f9cb44133cf476c670e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "BS=32\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "validation_dataloader = torch.utils.data.DataLoader(valset, batch_size=BS,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "BS=1024\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "train_dataloader_for_full_grad = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "9da31392596b4bfc8fa2030e7f50fa73",
      "7bdead393fb84605a7d1d0e91cda2a25",
      "203133ba6e6c4098aadf29be3f3e5a58",
      "ad846a92b6ad4465a76ced85115215c1",
      "8cb62341109c481ea02313ce40847ef5",
      "9bfe8ee639c1434c952d051859dd41df",
      "6b8e0e54e41f44569e95709d258e7e7e",
      "346776ad33454db4b3678d98763776a7"
     ]
    },
    "id": "EXAzG3o2rDxj",
    "outputId": "f0b01393-deb2-4a7d-9e07-c26e1232bb58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da31392596b4bfc8fa2030e7f50fa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model=torchvision.models.vgg16(pretrained=True)\n",
    "model.requires_grad_(False)\n",
    "import random\n",
    "\n",
    "model.classifier[6]=torch.nn.Linear(4096,10)\n",
    "device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model=model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xcufG7zrXE5"
   },
   "outputs": [],
   "source": [
    "optimizer=# ваш оптимизатор здесь\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC2nb-nqrob-"
   },
   "source": [
    "Добавим функции из семинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9q4H9wZKrtHF"
   },
   "outputs": [],
   "source": [
    "def get_loss(batch,model):\n",
    "\n",
    "  inputs, labels = batch\n",
    "\n",
    "  outputs = model(inputs.to(device))\n",
    "  loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "  return loss\n",
    "def get_accuracy(model,batch):\n",
    "  inputs, labels = batch\n",
    "\n",
    "  outputs = model(inputs.to(device))\n",
    "  \n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "   \n",
    "\n",
    "  return flat_accuracy(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "def flat_accuracy(preds, labels):\n",
    "  # print(preds.shape())\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  labels_flat = labels.flatten()\n",
    "  return np.sum(pred_flat == labels_flat) / len(labels_flat)                \n",
    "def validation(model):\n",
    "  print(\"Running Validation...\")\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    tmp_eval_accuracy = get_accuracy(model,batch)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "\n",
    "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps) )\n",
    "  # print(\" matthews_corrcoef_metric: {0:.2f}\".format(np.mean(matthews_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW39Rf2G2KBv"
   },
   "source": [
    "ваше описание здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1Jp3WBD2fFq"
   },
   "source": [
    "# Задание №3\n",
    "\n",
    "__*данное задание стоит 6 баллов*__\n",
    "\n",
    "__*каждый из экспериментов с определенным оптимизатором в каждом пункте стоит 1 балла, эксперименты без объяснения будут оцениваться .25 балла*__ \n",
    "\n",
    "Проведите исследование по оптимизации моделей([№1](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification) [№2](https://arxiv.org/pdf/1409.1556.pdf)) предложенных ниже, сравните скорости сходимости и полученные результаты для алгоритмов *SGD + Momentum*, *Adam*, *__ACClip__* с различными праметрами:\n",
    "- 1. lr - коэффициент обучения для всех элгоритмов (0.1, 0.01, 0.001, 0.0001) при фиксированных остальных гиперпараметрах \n",
    "  2. gamma - для SGD + momentum (0,9, 0,99, 0,5) для лучшего результата, полученного в пункте 1.\n",
    "  3. beta1, beta2 - для ACClip, ADAM - для различных значений (0,9, 0,99, 0,5) для лучшего результата, полученного в пункте 1.\n",
    "Объясните полученные Вами результаты.\n",
    "В задаче классификации изображений доучите уже предобученные веса , преждевренменно обучив последний линейный слой, для классификации изображений CIFAR10\n",
    "\n",
    "- Обоснуйте полученные результаты, опираясь на теорию лекции №8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLFiBTw1Wicj"
   },
   "source": [
    "В качестве датасета возьмем один одно из заданий, предложенных в качестве соревнований на [kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7DnNNswvX3Z"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://thigm85.github.io/data/cord19/cord19-query-title-label.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksvT2ioULBf9",
    "outputId": "f82a7b1e-03a6-45ee-ff4e-d73f05ea3838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DistilBERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print('Loading DistilBERT tokenizer...')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_vw4JxhLMfp",
    "outputId": "272ccf43-8ea8-4647-c365-e5ddfae17dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  Monophyletic Relationship between Severe Acute Respiratory Syndrome Coronavirus and Group 2 Coronaviruses\n",
      "Token IDs: [101, 18847, 21281, 7485, 2594, 3276, 2090, 5729, 11325, 16464, 8715, 21887, 23350, 1998, 2177, 1016, 21887, 23350, 2229, 102]\n"
     ]
    }
   ],
   "source": [
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# токенизируем предложения исходного датасета\n",
    "input_ids = []\n",
    "# For every sentence...\n",
    "for sent in df.title.values:\n",
    "    #   (1) токинизируем предложение.\n",
    "    #   (2) добавляем символ `[CLS]`в начало предложения.\n",
    "    #   (3) и символ `[SEP]`в конец.\n",
    "    #   (4) маркеруем все токены в их id\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # добавляем '[CLS]' и '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "print('Original: ', df.title.values[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sS5ns-x2MqN",
    "outputId": "8a687c97-0620-4eab-8887-e7b81efc2557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 125 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\\Done.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN =  max([len(sen) for sen in input_ids])+1\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "print('\\Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8yqNmwcy6F3"
   },
   "outputs": [],
   "source": [
    "# создадим attantion маску для кажого предложения\n",
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - если  ID = 0 тогда не стоит обрабатывать данный токен в процессе обучения, поскольку это паддинг\n",
    "    #   - если  ID > 0 тогда стоит использовать данный токен, поскольку он является частью предложения\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    attention_masks.append(att_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "A_9KnA3JwsGh",
    "outputId": "f813dda2-3219-4c54-a74b-cb4c7fa1c4d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7fd537145350>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBKEaeDQMSRY",
    "outputId": "50656e8f-f76f-4ef9-8f5e-ea0e7aa9d880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,df.label.values, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, df.label.values,\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "### даталоадер для вычисления полного градиента\n",
    "batch_size = 250#train_inputs.shape[0]\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader_for_full_grad = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "### для обучения\n",
    "batch_size = 16#train_inputs.shape[0]\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76dqayMsMXjw",
    "outputId": "1a697b95-6afa-4761-d0ae-999061f679c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JuB4rK2Mbfs",
    "outputId": "9fadda44-457f-4842-cb19-c94da885bde5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR-Jsit6MgoL"
   },
   "outputs": [],
   "source": [
    "###full_grad_dataloader\n",
    "batch_size = 250#train_inputs.shape[0]\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader_for_full_grad = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "### for training\n",
    "batch_size = 16#train_inputs.shape[0]\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler,  batch_size=len(validation_data)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9thIb80MmyD",
    "outputId": "80064212-89c9-4bce-909a-e8959b92bcb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим  DistilBertForSequenceClassification с одним выходным слоем и претрененными весами\n",
    "torch.manual_seed(15)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels = 2, \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRU2tnAyrdIO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(preds,labels):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7FGxaph1cdD"
   },
   "outputs": [],
   "source": [
    "optimizer =# исследуемый оптимизатор здесь\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9XJWQERM4Z3"
   },
   "outputs": [],
   "source": [
    "def training(model,n_epochs,optimizer):\n",
    "  for i in tqdm.tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "      optimizer.zero_grad()\n",
    "      loss=get_loss(batch,model)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    validation(model)\n",
    "\n",
    "def get_metrics(model,batch):\n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_input_mask = batch[1].to(device)\n",
    "  b_labels = batch[2].to(device)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(b_input_ids,  \n",
    "                      attention_mask=b_input_mask, \n",
    "                      labels=b_labels)\n",
    "  logits = torch.argmax(outputs.logits,1).detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "\n",
    "  return compute_metrics(logits, label_ids)\n",
    "           \n",
    "def validation(model):\n",
    "  print(\"Running Validation...\")\n",
    "  acc_set=[]\n",
    "  f1_set=[]\n",
    "  precision_set=[]\n",
    "  recall_set=[]\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    computed_results= get_metrics(model,batch)\n",
    "    acc_set.append(computed_results['accuracy'])\n",
    "    f1_set.append(computed_results['f1'])\n",
    "    precision_set.append(computed_results['precision'])\n",
    "    recall_set.append(computed_results['recall'])\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "\n",
    "  print(\"  Accuracy: {0:.2f}\".format(np.mean(acc_set)) )\n",
    "  print(\" f1=: {0:.2f}\".format(np.mean(f1_set)))\n",
    "  print(\" precision=: {0:.2f}\".format(np.mean(precision_set)))\n",
    "  print(\" recall=: {0:.2f}\".format(np.mean(recall_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9STw6ZVPcv9p"
   },
   "source": [
    "### Пункт №1(оптимизация языковой модели) \n",
    "Ваши эксперименты здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gko4t1E1c5Sa"
   },
   "source": [
    "Аналогичное задание для обработки изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtz8eENwc4lX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtOuyurFV0F4",
    "outputId": "2c0bf99f-553b-4ab2-d0a0-c777db6c1570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "BS=32\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfUkTYIJctdf"
   },
   "outputs": [],
   "source": [
    "model=torchvision.models.vgg32(pretrained=True)\n",
    "model.requires_grad_(False)\n",
    "\n",
    "model.classifier[6]=torch.nn.Linear(4096,10) #после небольшой адаптации весов последнего слоя все остальные веса предобученной модели имеет смысл разморозить\n",
    "device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model=model.to(device)\n",
    "optimizer=#оптимизатор здесь\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFr3EZ_SjUDi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Njqfx2Y5jjoV"
   },
   "outputs": [],
   "source": [
    "def get_loss(batch,model):\n",
    "\n",
    "  inputs, labels = batch\n",
    "\n",
    "  outputs = model(inputs.to(device))\n",
    "  loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "  return loss\n",
    "def get_accuracy(model,batch):\n",
    "  inputs, labels = batch\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs.to(device))\n",
    "  \n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "   \n",
    "\n",
    "  return flat_accuracy(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "def flat_accuracy(preds, labels):\n",
    "  # print(preds.shape())\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  labels_flat = labels.flatten()\n",
    "  return np.sum(pred_flat == labels_flat) / len(labels_flat)                \n",
    "def validation(model):\n",
    "  print(\"Running Validation...\")\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    tmp_eval_accuracy = get_accuracy(model,batch)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "\n",
    "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CByWROx3y-8w"
   },
   "source": [
    "### Пункт №2 (оптимизация модели обработки изображений)\n",
    "Ваши эксперименты здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6NTwNtekBoY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "203133ba6e6c4098aadf29be3f3e5a58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bfe8ee639c1434c952d051859dd41df",
      "max": 553433881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8cb62341109c481ea02313ce40847ef5",
      "value": 553433881
     }
    },
    "346776ad33454db4b3678d98763776a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b8e0e54e41f44569e95709d258e7e7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bdead393fb84605a7d1d0e91cda2a25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f7266c8a5194d1f88f1cfa4edf776aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc78da03b354499588de50590a0a67ac",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b39be4e467e44fdaa0c1071b63456d6f",
      "value": 170498071
     }
    },
    "8cb62341109c481ea02313ce40847ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9bfe8ee639c1434c952d051859dd41df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9da31392596b4bfc8fa2030e7f50fa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_203133ba6e6c4098aadf29be3f3e5a58",
       "IPY_MODEL_ad846a92b6ad4465a76ced85115215c1"
      ],
      "layout": "IPY_MODEL_7bdead393fb84605a7d1d0e91cda2a25"
     }
    },
    "ad846a92b6ad4465a76ced85115215c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_346776ad33454db4b3678d98763776a7",
      "placeholder": "​",
      "style": "IPY_MODEL_6b8e0e54e41f44569e95709d258e7e7e",
      "value": " 528M/528M [06:01&lt;00:00, 1.53MB/s]"
     }
    },
    "b39be4e467e44fdaa0c1071b63456d6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b969d72ac9694d76bac133f84a077c28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc78da03b354499588de50590a0a67ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2cb84aa531a4ffd9767b33f19d04ace": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c698d5d07ae54f9cb44133cf476c670e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f7266c8a5194d1f88f1cfa4edf776aa",
       "IPY_MODEL_ea9e54a6bb52434b87fa49e393f90d52"
      ],
      "layout": "IPY_MODEL_c2cb84aa531a4ffd9767b33f19d04ace"
     }
    },
    "ea9e54a6bb52434b87fa49e393f90d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b969d72ac9694d76bac133f84a077c28",
      "placeholder": "​",
      "style": "IPY_MODEL_f61f2a1e22b242fe810e8c5788bc43a4",
      "value": " 170499072/? [12:15&lt;00:00, 231665.17it/s]"
     }
    },
    "f61f2a1e22b242fe810e8c5788bc43a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
