{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEfPL00LH9E2"
      },
      "source": [
        "**Импортируем библиотеки**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTVOodb9ukhD",
        "outputId": "cdc6218a-7256-4b85-bd5d-e20dcc25b582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6FyGjL-gWCu",
        "outputId": "25b88711-0121-487a-b025-d017805c5691"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7B14-CphwSaC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from scipy.stats import norm as norm_d\n",
        "from scipy.stats import randint\n",
        "from scipy.optimize import minimize\n",
        "import copy\n",
        "import math\n",
        "import time\n",
        "from scipy.optimize import minimize\n",
        "from scipy.sparse.linalg import svds\n",
        "from scipy.linalg import svdvals\n",
        "import scipy\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import Optimizer\n",
        "import scipy.stats\n",
        "import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, DistilBertTokenizer,BertTokenizer,DistilBertForSequenceClassification\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMXkx6QBwpcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcef612a-c5b9-4978-d5b6-2cd90f024f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-31 20:28:20--  https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1645 (1.6K) [text/plain]\n",
            "Saving to: ‘functions.py’\n",
            "\n",
            "\rfunctions.py          0%[                    ]       0  --.-KB/s               \rfunctions.py        100%[===================>]   1.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-31 20:28:20 (39.5 MB/s) - ‘functions.py’ saved [1645/1645]\n",
            "\n",
            "--2023-05-31 20:28:21--  https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/datasets/a9a.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2329875 (2.2M) [text/plain]\n",
            "Saving to: ‘a9a.txt’\n",
            "\n",
            "a9a.txt             100%[===================>]   2.22M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-05-31 20:28:21 (302 MB/s) - ‘a9a.txt’ saved [2329875/2329875]\n",
            "\n",
            "--2023-05-31 20:28:21--  https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/datasets/a5a.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 458892 (448K) [text/plain]\n",
            "Saving to: ‘a5a.txt’\n",
            "\n",
            "a5a.txt             100%[===================>] 448.14K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-05-31 20:28:21 (66.7 MB/s) - ‘a5a.txt’ saved [458892/458892]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "if not pathlib.Path('./functions.py').is_file():\n",
        "  # !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/tests.py\n",
        "  !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/functions.py #alexrogozin12/opt_in_ml/blob/master/homework_5/functions.py\n",
        "  !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/datasets/a9a.txt\n",
        "  !wget https://raw.githubusercontent.com/alexrogozin12/opt_in_ml/master/homework_5/datasets/a5a.txt\n",
        "from functions import *\n",
        "# from tests import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVKKAAdsJcm9"
      },
      "source": [
        "### Решаемая задача\n",
        "Для удобства продублируем здесь задачу, которую вы решали ещё в прошлом домашнем задании:\n",
        "\n",
        "$$ F(x) = f(x) + R(x) = \\frac{1}{m}\\sum\\limits_{i=1}^m\\underbrace{\\left(\\log\\left(1 + \\exp\\left(-y_i\\cdot (Ax)_i\\right)\\right) + \\frac{l_2}{2}\\|x\\|_2^2\\right)}_{f_i(x)} + \\underbrace{l_1\\|x\\|_1}_{R(x)} \\to \\min\\limits_{x\\in\\mathbb{R}^n} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1CopnRWIQUj"
      },
      "source": [
        "предобработка данных, согласно прошлому заданию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "33gZlNon1F56"
      },
      "outputs": [],
      "source": [
        "def prepare_data(dataset):\n",
        "    filename = dataset + \".txt\"\n",
        "\n",
        "    data = load_svmlight_file(filename)\n",
        "    A, y = data[0], data[1]\n",
        "    m, n = A.shape\n",
        "    \n",
        "    if (2 in y) & (1 in y):\n",
        "        y = 2 * y - 3\n",
        "    if (2 in y) & (4 in y):\n",
        "        y = y - 3\n",
        "    assert((-1 in y) & (1 in y))\n",
        "    \n",
        "    sparsity_A = A.count_nonzero() / (m * n)\n",
        "    return A, y, m, n, sparsity_A\n",
        "\n",
        "def compute_L(dataset, A):\n",
        "    filename = dataset+\"_L.txt\"\n",
        "    file_path = Path(filename)\n",
        "    if file_path.is_file():\n",
        "        with open(filename, 'rb') as file:\n",
        "            L, average_L, worst_L = pickle.load(file)\n",
        "    else:\n",
        "        sigmas = svds(A, return_singular_vectors=False)\n",
        "        m = A.shape[0]\n",
        "        L = sigmas.max()**2 / (4*m)\n",
        "        \n",
        "        worst_L = 0\n",
        "        average_L = 0\n",
        "        denseA = A.toarray()\n",
        "        for i in range(m):\n",
        "            L_temp = (norm(denseA[i])**2)*1.0 / 4\n",
        "            average_L += L_temp / m\n",
        "            if L_temp > worst_L:\n",
        "                worst_L = L_temp\n",
        "        with open(filename, 'wb') as file:\n",
        "            pickle.dump([L, average_L, worst_L],file)\n",
        "    return L, average_L, worst_L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TPmoJ6H3gvL",
        "outputId": "f6155ed3-5c40-48d5-bb0f-9811711e124c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число функций в сумме:  32561 , размерность задачи:  123\n",
            "Константа гладкости всей функции:  1.5719196992226607\n",
            "Средняя константа гладкости     :  3.467276803535652\n",
            "Худшая константа гладкости      :  3.5\n",
            "Доля ненулевых элементов:  0.11275696922074716\n"
          ]
        }
      ],
      "source": [
        "dataset = \"a9a\"\n",
        "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
        "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
        "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
        "print(\"Константа гладкости всей функции: \", L)\n",
        "print(\"Средняя константа гладкости     : \", average_L)\n",
        "print(\"Худшая константа гладкости      : \", worst_L)\n",
        "print(\"Доля ненулевых элементов: \", sparsity_A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4KPH6OW1PYB"
      },
      "source": [
        "## Задание №1 \n",
        "\n",
        "__*данное задание стоит 3 балла*__ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptPsff6q6Df1"
      },
      "source": [
        "### Пункт №1\n",
        "\n",
        "__*данный пункт стоит 1 балл*__\n",
        "\n",
        "Реализуйте метод оптимизации Adam для логистической регрессии\n",
        "\n",
        "$$\n",
        "\\large\n",
        "\\begin{align}\n",
        "m_t &= \\beta_1 \\ m_{t-1} + (1 - \\beta_1)\\ g  \\\\ \n",
        "v_t &= \\beta_2 \\ v_{t-1} +  (1-\\beta_2)\\ g_{t}^2\\\\\n",
        "\\hat{m_t} &= \\frac{m_t}{1 - \\beta_1^t}\\\\\n",
        "\\hat{v_t} &= \\frac{v_t}{1 - \\beta_2^t}\\\\\n",
        "\\theta_t &= \\theta_{t-1} -  (\\frac{\\gamma}{\\sqrt{\\hat{v_t}} + \\delta}\\hat{m_t})\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "https://arxiv.org/pdf/1412.6980.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHOlsSwx6Cfu"
      },
      "outputs": [],
      "source": [
        "# from functions import *\n",
        "def adam(filename, x_init, A, y, gamma, beta1, beta2, delta=1e-8, \n",
        "         l2=0, sparse_full=True, sparse_stoch=False, l1=0, S=50, max_t=np.inf,\n",
        "         batch_size=1, indices=None, save_info_period=100, x_star=None):\n",
        "    m, n = A.shape\n",
        "    assert(len(x_init) == n)\n",
        "    assert(len(y) == m)\n",
        "    if indices is None:\n",
        "        indices = randint.rvs(low=0, high=m, size=min(int(S*m*1.0/batch_size), int(100000/batch_size))*batch_size,random_state=42)\n",
        "    indices_size = len(indices)\n",
        "    if x_star is None:\n",
        "        x_star = np.zeros(n)\n",
        "    ref_point = np.array(x_star) #если знаем решение, то ref_point поможет вычислять расстояние до него\n",
        "    x = np.array(x_init)\n",
        "    mm = np.zeros(n)\n",
        "    v = np.zeros(n)\n",
        "    \n",
        "    #эти массивы мы будем сохранять в файл\n",
        "    its = np.array([0])\n",
        "    tim = np.array([0.0])\n",
        "    data_passes = np.array([0.0])\n",
        "    func_val = np.array([F(x, [A, y, l2, sparse_full, l1])])\n",
        "    sq_distances = np.array([norm(x - ref_point) ** 2])\n",
        "    \n",
        "    t_start = time.time()\n",
        "    num_of_data_passes = 0.0\n",
        "    \n",
        "    if sparse_stoch:\n",
        "        A_for_batch = A\n",
        "    else:\n",
        "        A_for_batch = A.toarray()\n",
        "    \n",
        "    indices_counter = 0\n",
        "    \n",
        "    #метод\n",
        "    print(int(S*m/batch_size))\n",
        "    for it in range(int(S*m/batch_size)):\n",
        "        if indices_counter == indices_size:\n",
        "            indices_counter = 0\n",
        "            indices = randint.rvs(low=0, high=m, size=indices_size)\n",
        "        batch_ind = indices[indices_counter:(indices_counter+batch_size)]\n",
        "        indices_counter += batch_size\n",
        "        #ваш код здесь\n",
        "        g = logreg_grad(x, [A_for_batch[indices], y[indices], l2, sparse_stoch])\n",
        "        mm = beta1 * mm + (1 - beta1) * g\n",
        "        v = beta2 * v + (1 - beta2) * g ** 2\n",
        "        m_hat = m / (1-beta1**(it+1))\n",
        "        v_hat = v / (1-beta2**(it+1))\n",
        "        x = x - gamma*m_hat/(v_hat + delta)\n",
        "\n",
        "        num_of_data_passes += batch_size/m\n",
        "        if ((it + 1) % save_info_period == 0):\n",
        "            its = np.append(its, it + 1)\n",
        "            tim = np.append(tim, time.time() - t_start)\n",
        "            data_passes = np.append(data_passes, num_of_data_passes)\n",
        "            func_val = np.append(func_val, F(x, [A, y, l2, sparse_full, l1]))\n",
        "            sq_distances = np.append(sq_distances, norm(x - ref_point) ** 2)\n",
        "        if tim[-1] > max_t:\n",
        "            break\n",
        "    \n",
        "    if ((it + 1) % save_info_period != 0):\n",
        "        its = np.append(its, it + 1)\n",
        "        tim = np.append(tim, time.time() - t_start)\n",
        "        data_passes = np.append(data_passes, num_of_data_passes)\n",
        "        func_val = np.append(func_val, F(x, [A, y, l2, sparse_full, l1]))\n",
        "        sq_distances = np.append(sq_distances, norm(x - ref_point) ** 2)\n",
        "    \n",
        "    #сохранение результатов в файл\n",
        "    res = {'last_iter':x, 'func_vals':func_val, 'iters':its, 'time':tim, 'data_passes':data_passes,\n",
        "           'squared_distances':sq_distances}\n",
        "    if not os.path.isdir('./dump'):\n",
        "      os.mkdir('./dump')\n",
        "    with open(\"dump/\"+filename+\"_Adam_gamma_\"+str(gamma)+\"_beta1_\"+str(beta1)+\"_beta2_\"+str(beta2)\n",
        "              +\"_l2_\"+str(l2)+\"_l1_\"+str(l1)+\"_num_of_epochs_\"+str(S)\n",
        "              +\"_batch_size_\"+str(batch_size)+\".txt\", 'wb') as file:\n",
        "        pickle.dump(res, file)\n",
        "\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "pOwliBam5gMx",
        "outputId": "8d3413f1-3e6a-4c6c-cde7-718372ab8cb1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32561000\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-56589c010587>\u001b[0m in \u001b[0;36madam\u001b[0;34m(filename, x_init, A, y, gamma, beta1, beta2, delta, l2, sparse_full, sparse_stoch, l1, S, max_t, batch_size, indices, save_info_period, x_star)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mindices_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#ваш код здесь\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mA_for_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_stoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/functions.py\u001b[0m in \u001b[0;36mlogreg_grad\u001b[0;34m(x, args)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlogreg_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "np.random.seed(10)\n",
        "x_init = np.ones(n)\n",
        "dataset = \"a9a\"\n",
        "filename=dataset+\"_x_init_all_ones\"\n",
        "l2 = L / 10000\n",
        "l1 = L / 1000\n",
        "batch_size = 10\n",
        "gamma_gd = 1.0/((L+l2))\n",
        "gamma = 1.0/(6*(L+l2))\n",
        "gamma_schedule = [gamma, 10, 0.5]\n",
        "S = 10000\n",
        "beta1 = 0.9\n",
        "gamma_adam = 0.001\n",
        "gamma_adagrad = 1.0\n",
        "beta2 = 0.99\n",
        "indices = None\n",
        "\n",
        "res = adam(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma_adam,\n",
        "           beta1=beta1, beta2=beta2, l2=l2, \n",
        "           sparse_full=False, sparse_stoch=False, l1=l1, S=S, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rJHWmyF5zq4"
      },
      "source": [
        "Тестируем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "RW4PuIDpBYRt",
        "outputId": "54a35a95-3200-4f08-a8b6-8e8930a7d634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-31 08:42:44--  https://raw.githubusercontent.com/pcgames/datasets/master/tests/Adam_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13025933 (12M) [application/octet-stream]\n",
            "Saving to: ‘Adam_test.txt’\n",
            "\n",
            "Adam_test.txt       100%[===================>]  12.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-31 08:42:45 (118 MB/s) - ‘Adam_test.txt’ saved [13025933/13025933]\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4f07bbdd866a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Adam_test.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtest_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'что-то не так...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
          ]
        }
      ],
      "source": [
        "if not pathlib.Path('./Adam_test.txt').is_file():\n",
        "  !wget https://raw.githubusercontent.com/pcgames/datasets/master/tests/Adam_test.txt\n",
        "with open('./Adam_test.txt','rb') as f:\n",
        "  test_res=pickle.load(f)\n",
        "assert (abs(test_res['last_iter']-res['last_iter'])<1e-6).all(),'что-то не так...'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9LECLs0i-eF"
      },
      "source": [
        "### Пункт №2\n",
        "\n",
        "__*данный пункт стоит 1 балл*__\n",
        "\n",
        "Сравните результаты данного экспермента с результатами, полученными в прошлом домашнем задании для методов  __SGD__, __SVRG__ и ускоренным методом Нестерова (метод __FISTA__ без prox_r):\n",
        "- Нарисуйте графики сходимости\n",
        "- Исходя из теории, полученной на лекции, обоснуйте результаты, полученные в эксперименте, а так же сделайте выводы о работе данных методов на поставленной задаче."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WI6ng3c5BAB"
      },
      "outputs": [],
      "source": [
        "from algorithms import *\n",
        "\n",
        "res_sgd = sgd_const_stepsize(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
        "     sparse_full=False, sparse_stoch=False, \n",
        "     l1=l1, S=S, max_t=np.inf, batch_size=batch_size)\n",
        "\n",
        "res_svrg = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
        "     sparse_full=False, sparse_stoch=False, \n",
        "     l1=l1, S=S, M=M, max_t=np.inf,\n",
        "     batch_size=batch_size, indices=None)\n",
        "\n",
        "res_fista = FISTA(filename=filename, x_init=x_init, A=A, y=y, L=L+l2, mu=l2, \n",
        "     sparse=False, l1=l1, S=S, max_t=np.inf)\n",
        "# plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bakpt6NqfoeE"
      },
      "outputs": [],
      "source": [
        "plt.plot(res['func_vals'], label='Adam')\n",
        "plt.plot(res_sgd['func_vals'], label='SGD')\n",
        "plt.plot(res_svrg['func_vals'], label='SVRG')\n",
        "\n",
        "plt.plot(res_fista['func_vals'], label='FISTA')\n",
        "plt.legend()\n",
        "\n",
        "# dataset = \"a9a\"\n",
        "# filename=dataset+\"_x_init_all_ones\"\n",
        "\n",
        "# methods = [\n",
        "#          ['Adam', [l2, l1, S], f', S ={S}, ', None]\n",
        "#          ['SGD', [l2, l1, S], f', S ={S}, ', None]\n",
        "#          ['SVRG', [l2, l1, S], f', S ={S}, ', None]\n",
        "#          ['FISTA', [l2, l1, S], f', S ={S}, ', None]\n",
        "# ]\n",
        "\n",
        "# mode_y = 'squared_distances'\n",
        "# mode_x = 'time'\n",
        "# figsize = (12, 8)\n",
        "# fontsize = 20\n",
        "# title = dataset+\", (m,n) = (\"+str(m)+\",\"+str(n)+\"), l2 = L/\"+str(int(L/l2))+\", l1 = L/\"+str(int(L/l1))\n",
        "\n",
        "# args_for_plots = [dataset, filename, mode_y, mode_x, figsize, fontsize, title, methods]\n",
        "# make_plots(args=args_for_plots)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMYsaZsnhqkt"
      },
      "source": [
        "### Пункт №3 \n",
        "\n",
        "__*данный пункт стоит 1 балл*__\n",
        "\n",
        "Проведите аналогичный эксперимент на другом датасете, сохраните результат и отправьте его вместе с домашним заданием"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GviwusXrhTEs",
        "outputId": "10f51ad0-79dd-4c35-88c8-86856b24657b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Число функций в сумме:  6414 , размерность задачи:  122\n",
            "Константа гладкости всей функции:  1.5740271677041653\n",
            "Средняя константа гладкости     :  3.466596507639382\n",
            "Худшая константа гладкости      :  3.5\n",
            "Доля ненулевых элементов:  0.11365890188982093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%%time` not found.\n"
          ]
        }
      ],
      "source": [
        "dataset = \"a5a\"\n",
        "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
        "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
        "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
        "print(\"Константа гладкости всей функции: \", L)\n",
        "print(\"Средняя константа гладкости     : \", average_L)\n",
        "print(\"Худшая константа гладкости      : \", worst_L)\n",
        "print(\"Доля ненулевых элементов: \", sparsity_A)\n",
        "%%time\n",
        "np.random.seed(10)\n",
        "x_init = np.ones(n)\n",
        "dataset = \"a5a\"\n",
        "filename=dataset+\"_x_init_all_ones\"\n",
        "l2 = L / 10000\n",
        "l1 = L / 1000\n",
        "batch_size = 10\n",
        "gamma_gd = 1.0/((L+l2))\n",
        "gamma = 1.0/(6*(L+l2))\n",
        "gamma_schedule = [gamma, 10, 0.5]\n",
        "S = 10000\n",
        "beta1 = 0.9\n",
        "gamma_adam = 0.001\n",
        "gamma_adagrad = 1.0\n",
        "beta2 = 0.99\n",
        "indices = None\n",
        "\n",
        "res = adam(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma_adam,\n",
        "           beta1=beta1, beta2=beta2, l2=l2, \n",
        "           sparse_full=False, sparse_stoch=False, l1=l1, S=S, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMw5aUP_1Zrg"
      },
      "source": [
        "## Задание №2\n",
        "\n",
        "__*данное задание стоит 4 балла*__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTV5--U-GYre"
      },
      "source": [
        "### Пункт №1\n",
        "__*данный пункт стоит 2 балла*__\n",
        "\n",
        "реализовать метод оптимизации ACClip, о котором рассказывалось на лекции  \n",
        "$$\n",
        "\\large\n",
        "\\begin{align}\n",
        "for \\, k=&1\\cdots N- количество \\, эпох\\, прохода\\, по\\, данным\\\\\n",
        "&for \\, t=1\\cdots T- количество \\, частей\\, , на \\, которое \\,разделен \\, весь \\, датасет\\,рандомным\\,образом\\\\\n",
        "&\\,\\,\\,\\,\\,\\,\\,\\,m_t = \\beta_1 \\ m_{t-1} + (1 - \\beta_1)\\ g_t \\\\ \n",
        "&\\,\\,\\,\\,\\,\\,\\,\\, \\tau^\\alpha_t = \\beta_2 \\tau_{t-1}^\\alpha +  (1-\\beta_2)\\ g_{t}^\\alpha  \\\\\n",
        "&\\,\\,\\,\\,\\,\\,\\,\\,\\hat{g_t} = \\min\\{\\frac{\\tau_t}{|m_t|+\\epsilon},1\\}m_t \\\\\n",
        "%\\hat{v_t} = \\frac{v_t}{1 - \\beta^t}\\\\\n",
        "&\\,\\,\\,\\,\\,\\,\\,\\,\\theta_t = \\theta_{t-1} -  \\eta \\hat{g_t}\\\\\n",
        "& endfor\\\\\n",
        "endfor\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "https://arxiv.org/pdf/1912.03194.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b3-5-6U-Bu2j"
      },
      "outputs": [],
      "source": [
        "class ACC(Optimizer):\n",
        "    def __init__(self, \n",
        "                 params, \n",
        "                 lr=1e-4, \n",
        "                 betas=(0.9, 0.99), \n",
        "                 eps=1e-5,\n",
        "                 w=1e-5,\n",
        "                 alpha=2):\n",
        "\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,weight_decay=w,alpha=2)\n",
        "        # тут вызываем конструктор базового класса и сохраняем параметры обучения\n",
        "        # их можно достать через self.param_groups\n",
        "        super(ACC, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self,closure=None):\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            # итерируемся по всем группам параметров нашей сети\n",
        "            # тут можно вытащить сохраненные параметры в группе\n",
        "            beta1, beta2 = group['betas'] \n",
        "            eps = group['eps']\n",
        "            w = group['weight_decay']\n",
        "            lr = group['lr']\n",
        "            alpha=group['alpha']\n",
        "\n",
        "            for p in group['params']:\n",
        "                # итерируемся по всем парамерам в данно группе\n",
        "                # если нет градиента по параметрам скипаем его\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                # забираем тензор градиента    \n",
        "                grad = p.grad.data\n",
        "                \n",
        "                # тут храняться значения, которые мы расчитываем в процессе \n",
        "                # по каждому параметру в группе нужно расчитывать свои значения\n",
        "                state = self.state[p]\n",
        "\n",
        "                # если параметры мы еще не записали инициализируем их значения\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    #начальное значение m\n",
        "                    state['momentum'] = torch.zeros_like(p.data)\n",
        "\n",
        "                    # начальное значение \\tau^{\\alpha}\n",
        "                    state['t'] = torch.zeros_like(p.data)\n",
        "\n",
        "\n",
        "                t, m = state['t'], state['momentum']\n",
        "                        \n",
        "                # запоминаем шаг\n",
        "                state['step'] += 1\n",
        "                # Считаем параметры.\n",
        "                # g = log\n",
        "                m = beta1 * m + (1 - beta1) * grad\n",
        "                t = torch.pow(beta2*torch.pow(t, alpha)+(1-beta2)*(grad.abs()**alpha), 1./alpha)\n",
        "                g_hat = (t/(m.abs()+eps)).clamp(min=0.0, max=1.0)*m\n",
        "                \n",
        "                # обновляем веса в p.data, \n",
        "                w = w - lr * g_hat\n",
        "\n",
        "                \n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlAvmWSdyoyX"
      },
      "source": [
        "Протестируем реализованный метод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qexxOhQSj8Mu",
        "outputId": "73214dc0-77d4-48e9-c154-1f20dfd04f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-31 20:28:34--  https://raw.githubusercontent.com/pcgames/datasets/master/apples_pears.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42590 (42K) [text/plain]\n",
            "Saving to: ‘apples_pears.csv’\n",
            "\n",
            "apples_pears.csv    100%[===================>]  41.59K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-05-31 20:28:34 (18.6 MB/s) - ‘apples_pears.csv’ saved [42590/42590]\n",
            "\n",
            "--2023-05-31 20:28:34--  https://raw.githubusercontent.com/pcgames/datasets/master/tests/ACC_test.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1153 (1.1K) [application/octet-stream]\n",
            "Saving to: ‘ACC_test.pt’\n",
            "\n",
            "ACC_test.pt         100%[===================>]   1.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-31 20:28:34 (63.3 MB/s) - ‘ACC_test.pt’ saved [1153/1153]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "if not pathlib.Path('./apples_pears.csv').is_file():\n",
        "  !wget https://raw.githubusercontent.com/pcgames/datasets/master/apples_pears.csv\n",
        "  !wget https://raw.githubusercontent.com/pcgames/datasets/master/tests/ACC_test.pt\n",
        "\n",
        "\n",
        "data=pd.read_csv('./apples_pears.csv')\n",
        "X = torch.FloatTensor(data.iloc[:,:2].values) # матрица объекты-признаки\n",
        "y = torch.LongTensor(data['target'].values.reshape((-1, 1))).view(-1)  # классы (столбец из нулей и единиц)\n",
        "\n",
        "torch.manual_seed(10)\n",
        "np.random.seed(10)\n",
        "NN=nn.Sequential(nn.Linear(X.shape[1],\n",
        "                                torch.unique(y).shape.numel()\n",
        "                                ),\n",
        "                       )\n",
        "loss_fn=torch.nn.CrossEntropyLoss(size_average=False)\n",
        "\n",
        "learning_rate = 0.01  \n",
        "optimizer = ACC(NN.parameters(), lr=learning_rate)\n",
        "for t in range(500):\n",
        "    y_pred=NN.forward(X)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "testing_NN=nn.Sequential(nn.Linear(X.shape[1],\n",
        "                                torch.unique(y).shape.numel()\n",
        "                                ),\n",
        "                       )\n",
        "testing_NN.load_state_dict(torch.load('./ACC_test.pt'))\n",
        "a=testing_NN.parameters()\n",
        "\n",
        "for b in NN.parameters():\n",
        "  c=next(a).data.clone()\n",
        "  d=b.data.clone()\n",
        "  assert ((c-d).abs()<1e-6).values, 'что-то не так!'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckwO8PMK9WqI"
      },
      "source": [
        "### Пункт №2\n",
        "__*в данном пункте описание каждого эксперимента стоит 1 балл*__\n",
        "\n",
        "Проведите эксперименты ,аналогичные проведенным на семинаре, с использованием алгоритма ACClip:\n",
        "- Получите распределение норм разностей стох. и полного градиентов для языковой модели bert на датасете CoLA\n",
        "\n",
        "- Получите распредиление норм разностей стох. и полного градиентов на модели VGG16 для датасета CIFAR10\n",
        "\n",
        "Сравните результаты, с результатами полученными для алгоритмов Adam SGD+momentum и обоснуйте результаты исходя из материалов, полученных на лекции №8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2yqdkzeQJnP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj3--oa6QNCM"
      },
      "source": [
        "#### Предобработка данных\n",
        "\n",
        "Загрузим датасет из семинара и проведем его предобработку "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5PPNtJRRzzZ",
        "outputId": "ce29fe16-8c80-4a0a-cfb4-ab9c5410b771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=4c5685eb0b2df0eccfc078a870a73cb203f8e7af6784e0f0e73fbda977b1b495\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Downloading dataset\n",
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ],
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "!pip install wget\n",
        "import wget\n",
        "import os\n",
        "print('Downloading dataset')\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "  wget.download(url, './cola_public_1.1.zip')\n",
        "  if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xE9fibOyQecP",
        "outputId": "60e2084c-26f6-4754-faba-0e5f877994a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "0               gj04      1         NaN   \n",
              "1               gj04      1         NaN   \n",
              "2               gj04      1         NaN   \n",
              "3               gj04      1         NaN   \n",
              "4               gj04      1         NaN   \n",
              "...              ...    ...         ...   \n",
              "8546            ad03      0           *   \n",
              "8547            ad03      0           *   \n",
              "8548            ad03      1         NaN   \n",
              "8549            ad03      1         NaN   \n",
              "8550            ad03      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "0     Our friends won't buy this analysis, let alone...  \n",
              "1     One more pseudo generalization and I'm giving up.  \n",
              "2      One more pseudo generalization or I'm giving up.  \n",
              "3        The more we study verbs, the crazier they get.  \n",
              "4             Day by day the facts are getting murkier.  \n",
              "...                                                 ...  \n",
              "8546                   Poseidon appears to own a dragon  \n",
              "8547                     Digitize is my happiest memory  \n",
              "8548                     It is easy to slay the Gorgon.  \n",
              "8549       I had the strangest feeling that I knew you.  \n",
              "8550                What all did you get for Christmas?  \n",
              "\n",
              "[8551 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-876f38c9-6179-46b7-82b2-e8148a604fa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8546</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8547</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8548</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8549</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8550</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8551 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-876f38c9-6179-46b7-82b2-e8148a604fa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-876f38c9-6179-46b7-82b2-e8148a604fa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-876f38c9-6179-46b7-82b2-e8148a604fa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t',\n",
        "                 header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaRCf8v3R90B"
      },
      "source": [
        "Поскольку в данной части задания мы будем использовать тот же самый [CoLA Dataset](https://nyu-mll.github.io/CoLA/#) и ту же самую [модель](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification), проведем аналогичную предобработку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hSxGskXeRm-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ee6f2d-1737-423b-a7ef-826656c157df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n",
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n",
            "\n",
            "Padding/truncating all sentences to 48 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\\Done.\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# токенизируем предложения исходного датасета\n",
        "input_ids = []\n",
        "# For every sentence...\n",
        "for sent in df.sentence.values:\n",
        "    #   (1) токинизируем предложение.\n",
        "    #   (2) добавляем символ `[CLS]`в начало предложения.\n",
        "    #   (3) и символ `[SEP]`в конец.\n",
        "    #   (4) маркеруем все токены в их id\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, # добавляем '[CLS]' и '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "print('Original: ', df.sentence.values[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "\n",
        "MAX_LEN =  max([len(sen) for sen in input_ids])+1\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "print('\\Done.')\n",
        "# создадим attantion маску для кажого предложения\n",
        "attention_masks = []\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - если  ID =0 тогда не стоит обрабатывать данный токен в процессе обучения, поскольку это паддинг\n",
        "    #   -  если  ID >0 тогда стоит использовать данный токен, поскольку он является частью предложения\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    attention_masks.append(att_mask)\n",
        "\n",
        "\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,df.label.values, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, df.label.values,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "### даталоадер для вычисления полного градиента\n",
        "batch_size = 250#train_inputs.shape[0]\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader_for_full_grad = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "### для обучения\n",
        "batch_size = 16#train_inputs.shape[0]\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0me_7jZXRm71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982,
          "referenced_widgets": [
            "6d8e6b1cf32c42c09bcf29b88143ef8c",
            "efc1e4f258304c668f4ea2a3d40e2d32",
            "436e9251ced54b8ea85246933354c49a",
            "7560929a396d4568ad3037640ca812d4",
            "bbd5c661289145eca1731ff77436527c",
            "b99b98af3639449588e40c9874e11a4f",
            "f783b9b0daa84df080021235174acd61",
            "1f69e27d281246af8dad918c0629c638",
            "4d98b18560c74a04a482bf7607922af7",
            "dfac346bea444f8690cb905619ba100d",
            "0e9f091bea8f4b1895a2c69b937ad211"
          ]
        },
        "outputId": "66dbd9fe-0efb-4511-ef2b-43f966990522"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d8e6b1cf32c42c09bcf29b88143ef8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "torch.manual_seed(15)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "  \"bert-base-uncased\", # 12-ти слойная модель BERT с предобученными весами\n",
        "  num_labels = 2, # количество выходных хначений для бинарной классификации  \n",
        "  output_attentions = False, # true, если необходимо брать attention веса модели.\n",
        "  output_hidden_states = False, #true, если необходимо брать значения со скрытых слоёв.\n",
        ")\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "59uq_rfFRm49"
      },
      "outputs": [],
      "source": [
        "optimizer = ACC(model.parameters(),\n",
        "                 lr=1e-4, \n",
        "                 betas=(0.9, 0.99), \n",
        "                 eps=1e-5,\n",
        "                 w=1e-5,\n",
        "                 alpha=2)#воспользуйтесь Вашим оптимизатором\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq3yMSWg15_t"
      },
      "source": [
        "#### Эксперимент №1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWTa8AK5P7hT"
      },
      "source": [
        "**Функции**\n",
        "\n",
        "воспользуемся функциями из семинарского ноутбука"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yOlwS_KUP6PL"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "    \n",
        "import time\n",
        "import datetime\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "def get_batch_grad(model):\n",
        "  gr=[]\n",
        "  for i in model.parameters():\n",
        "    if i.requires_grad:\n",
        "      gr.append(i.grad.view(-1))\n",
        "  return torch.cat(gr)\n",
        "def get_loss(batch,model):\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "  outputs = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "\n",
        "  loss=outputs[0]\n",
        "  return loss\n",
        "def compute_full_grad(model):\n",
        "  fully_grad=[]\n",
        "  for step, batch in enumerate(train_dataloader_for_full_grad):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss=get_loss(batch,model)\n",
        "    loss.backward()\n",
        "\n",
        "    fully_grad = fully_grad + get_batch_grad(model) * \\\n",
        "        train_dataloader_for_full_grad.batch_size if fully_grad!=[] \\\n",
        "            else get_batch_grad(model) * train_dataloader_for_full_grad.batch_size\n",
        "\n",
        "  print(\"full grad computed\")\n",
        "  return fully_grad / (step * train_dataloader_for_full_grad.batch_size)\n",
        "def draw_norm_hist(norm_diffs):\n",
        "  bins_n=500\n",
        "  counts, bins=np.histogram(norm_diffs,bins_n)\n",
        "  mu = np.mean(norm_diffs)\n",
        "  sigma = np.sqrt(np.mean((norm_diffs - mu)**2))\n",
        "  temp2 = np.linspace(0, bins[-1], bins_n)\n",
        "  plt.semilogy(temp2, scipy.stats.norm.pdf(temp2, mu, sigma), linewidth=2, color='red', marker='d',\n",
        "            markersize = 15, \n",
        "            markevery=range(0, bins_n, 100))\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.yscale('log')\n",
        "  plt.show()\n",
        "\n",
        "def compute_norm_diffs(model):\n",
        "  full_grad=compute_full_grad(model)\n",
        "  mini_norms=[]\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    loss=get_loss(batch,model)\n",
        "    loss.backward()\n",
        "    mini_norms.append((get_batch_grad(model)-full_grad).norm().item())\n",
        "  print(\"norm diffs computed\")\n",
        "\n",
        "  return np.array(mini_norms)\n",
        "\n",
        "def training_and_drawing(model,n_epochs,optimizer):\n",
        "  norm_diffs_every_epoch=[]\n",
        "  for i in tqdm.tqdm(range(n_epochs)):\n",
        "    model.eval()\n",
        "    norm_diffs_every_epoch.append(compute_norm_diffs(model))\n",
        "    if i:\n",
        "      draw_norm_hist(norm_diffs_every_epoch[-1])\n",
        "    else:\n",
        "      draw_norm_hist(norm_diffs_every_epoch)\n",
        "    print(\"start_training\")\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "      loss=get_loss(batch,model)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  validation(model)\n",
        "  return norm_diffs_every_epoch\n",
        "\n",
        "def get_accuracy(model,batch):\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "  # print(outputs.logits)\n",
        "  logits = outputs.logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "\n",
        "        \n",
        "  return flat_accuracy(logits, label_ids)\n",
        "def flat_accuracy(preds, labels):\n",
        "  # print(preds.shape())\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat),matthews_corrcoef(labels_flat, pred_flat)                \n",
        "def validation(model):\n",
        "  print(\"Running Validation...\")\n",
        "  matthews_set=[]\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    tmp_eval_accuracy,matthew = get_accuracy(model,batch)\n",
        "    matthews_set.append(matthew)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "\n",
        "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps) )\n",
        "  print(\" matthews_corrcoef_metric: {0:.2f}\".format(np.mean(matthews_set)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "vazLf3eYfHwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "1b70592a-9af4-4c0c-afa0-5e1a7237639a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7fcb6c12e21b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm_diffs_every_epoch_Adam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_and_drawing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-a3ef51407c86>\u001b[0m in \u001b[0;36mtraining_and_drawing\u001b[0;34m(model, n_epochs, optimizer)\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mnorm_diffs_every_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_norm_diffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0mdraw_norm_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_diffs_every_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-a3ef51407c86>\u001b[0m in \u001b[0;36mcompute_norm_diffs\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_norm_diffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   \u001b[0mfull_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_full_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m   \u001b[0mmini_norms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-a3ef51407c86>\u001b[0m in \u001b[0;36mcompute_full_grad\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-a3ef51407c86>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(batch, model)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mb_input_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   outputs = model(b_input_ids, \n\u001b[0m\u001b[1;32m     29\u001b[0m                       \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DistilBertForSequenceClassification.forward() got an unexpected keyword argument 'token_type_ids'"
          ]
        }
      ],
      "source": [
        "norm_diffs_every_epoch_Adam=training_and_drawing(model,epochs,optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-rctCPqqCKa"
      },
      "source": [
        "#### Эксперимент №2 \n",
        "Сделаем аналогичный эксперимент для изображений\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-7DYgW8qSsG",
        "outputId": "360913de-9a52-4c26-e357-bbc352a471ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12959905.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "BS=32\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "valset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "validation_dataloader = torch.utils.data.DataLoader(valset, batch_size=BS,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "BS=1024\n",
        "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "#                                         download=True, transform=transform)\n",
        "train_dataloader_for_full_grad = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXAzG3o2rDxj",
        "outputId": "75cbdb48-7fcd-4f9c-fa33-ec94127aa64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:01<00:00, 310MB/s]\n"
          ]
        }
      ],
      "source": [
        "model=torchvision.models.vgg16(pretrained=True)\n",
        "model.requires_grad_(False)\n",
        "import random\n",
        "\n",
        "model.classifier[6]=torch.nn.Linear(4096,10)\n",
        "device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model=model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6xcufG7zrXE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae18ec9c-6359-40c2-e884-d08a1533afe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "optimizer=ACC(model.parameters(),\n",
        "                 lr=1e-4, \n",
        "                 betas=(0.9, 0.99), \n",
        "                 eps=1e-5,\n",
        "                 w=1e-5,\n",
        "                 alpha=2)# ваш оптимизатор здесь\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC2nb-nqrob-"
      },
      "source": [
        "Добавим функции из семинара"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9q4H9wZKrtHF"
      },
      "outputs": [],
      "source": [
        "def get_loss(batch,model):\n",
        "\n",
        "  inputs, labels = batch\n",
        "\n",
        "  outputs = model(inputs.to(device))\n",
        "  loss = criterion(outputs, labels.to(device))\n",
        "\n",
        "  return loss\n",
        "def get_accuracy(model,batch):\n",
        "  inputs, labels = batch\n",
        "\n",
        "  outputs = model(inputs.to(device))\n",
        "  \n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "   \n",
        "\n",
        "  return flat_accuracy(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
        "def flat_accuracy(preds, labels):\n",
        "  # print(preds.shape())\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)                \n",
        "def validation(model):\n",
        "  print(\"Running Validation...\")\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    tmp_eval_accuracy = get_accuracy(model,batch)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "\n",
        "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps) )\n",
        "  # print(\" matthews_corrcoef_metric: {0:.2f}\".format(np.mean(matthews_set)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEjomvaRj2WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW39Rf2G2KBv"
      },
      "source": [
        "ваше описание здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1Jp3WBD2fFq"
      },
      "source": [
        "# Задание №3\n",
        "\n",
        "__*данное задание стоит 6 баллов*__\n",
        "\n",
        "__*каждый из экспериментов с определенным оптимизатором в каждом пункте стоит 1 балла, эксперименты без объяснения будут оцениваться .25 балла*__ \n",
        "\n",
        "Проведите исследование по оптимизации моделей([№1](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification) [№2](https://arxiv.org/pdf/1409.1556.pdf)) предложенных ниже, сравните скорости сходимости и полученные результаты для алгоритмов *SGD + Momentum*, *Adam*, *__ACClip__* с различными праметрами:\n",
        "- 1. lr - коэффициент обучения для всех элгоритмов (0.1, 0.01, 0.001, 0.0001) при фиксированных остальных гиперпараметрах \n",
        "  2. gamma - для SGD + momentum (0,9, 0,99, 0,5) для лучшего результата, полученного в пункте 1.\n",
        "  3. beta1, beta2 - для ACClip, ADAM - для различных значений (0,9, 0,99, 0,5) для лучшего результата, полученного в пункте 1.\n",
        "Объясните полученные Вами результаты.\n",
        "В задаче классификации изображений доучите уже предобученные веса , преждевренменно обучив последний линейный слой, для классификации изображений CIFAR10\n",
        "\n",
        "- Обоснуйте полученные результаты, опираясь на теорию лекции №8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLFiBTw1Wicj"
      },
      "source": [
        "В качестве датасета возьмем один одно из заданий, предложенных в качестве соревнований на [kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "v7DnNNswvX3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e0699c05-fd66-4e3d-adab-3a5e5ca8ae8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                query                                              title  \\\n",
              "0  coronavirus origin  Monophyletic Relationship between Severe Acute...   \n",
              "1  coronavirus origin  Comprehensive overview of COVID-19 based on cu...   \n",
              "2  coronavirus origin  The SARS, MERS and novel coronavirus (COVID-19...   \n",
              "3  coronavirus origin  Evidence for zoonotic origins of Middle East r...   \n",
              "4  coronavirus origin             Deadly virus effortlessly hops species   \n",
              "\n",
              "   label  \n",
              "0      1  \n",
              "1      1  \n",
              "2      1  \n",
              "3      1  \n",
              "4      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32519750-2e5a-4921-ae29-1b634e966096\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coronavirus origin</td>\n",
              "      <td>Monophyletic Relationship between Severe Acute...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coronavirus origin</td>\n",
              "      <td>Comprehensive overview of COVID-19 based on cu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus origin</td>\n",
              "      <td>The SARS, MERS and novel coronavirus (COVID-19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coronavirus origin</td>\n",
              "      <td>Evidence for zoonotic origins of Middle East r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coronavirus origin</td>\n",
              "      <td>Deadly virus effortlessly hops species</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32519750-2e5a-4921-ae29-1b634e966096')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32519750-2e5a-4921-ae29-1b634e966096 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32519750-2e5a-4921-ae29-1b634e966096');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://thigm85.github.io/data/cord19/cord19-query-title-label.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "01e628655d71447ab34e606b03f5b661",
            "ff63dff9bd16434eadd245b318ab9d10",
            "365a9d8df56a49b38a0ec7293bd6862f",
            "aa4fd036b7624f43a56c6eb2822a6c03",
            "f12a061750c44b86a87c02f6e2fb540f",
            "893cf9cfe27e43c4aa0344559da80435",
            "3b2fb1f6fbd64146beadcec27ffd39a3",
            "4edec69bef3a44858350b8ece02dd6cf",
            "578726e51a714144a112783dfed24469",
            "888d729505e34c5aac61c82b095ed5fa",
            "c57d2b0f5a2b47f786bfa11e5e2acdee",
            "9f312297f9de49b0a55f7634972d9b04",
            "a858a49c39a647bbb8684d477a5ecdf8",
            "e0fc84235bbd4647aa0850e639320114",
            "97c57d9f67794c5f992f5c7f6f16be68",
            "a06adac1e6234033943f806d5e47da51",
            "916215d6b55b4d79b374cdbf194bc07c",
            "edbecd9a1f314f6dab26e9279cd27f09",
            "09f1e456db1044f48186276b8d8f9fbd",
            "fe5aed206b12467daaac2b9c5c53aaa7",
            "89ad300e1f194253b30ba29f2b32b6bc",
            "1d61aede530f45edb9d885ea9759e0c9"
          ]
        },
        "id": "ksvT2ioULBf9",
        "outputId": "31b38f97-8c07-4d8c-e47b-95b3e9d45499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DistilBERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01e628655d71447ab34e606b03f5b661"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f312297f9de49b0a55f7634972d9b04"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('Loading DistilBERT tokenizer...')\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_vw4JxhLMfp",
        "outputId": "960ab7b0-7c9b-4bb3-8ec8-c87c510533d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n",
            "Original:  Monophyletic Relationship between Severe Acute Respiratory Syndrome Coronavirus and Group 2 Coronaviruses\n",
            "Token IDs: [101, 18847, 21281, 7485, 2594, 3276, 2090, 5729, 11325, 16464, 8715, 21887, 23350, 1998, 2177, 1016, 21887, 23350, 2229, 102]\n"
          ]
        }
      ],
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# токенизируем предложения исходного датасета\n",
        "input_ids = []\n",
        "# For every sentence...\n",
        "for sent in df.title.values:\n",
        "    #   (1) токинизируем предложение.\n",
        "    #   (2) добавляем символ `[CLS]`в начало предложения.\n",
        "    #   (3) и символ `[SEP]`в конец.\n",
        "    #   (4) маркеруем все токены в их id\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, # добавляем '[CLS]' и '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "print('Original: ', df.title.values[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sS5ns-x2MqN",
        "outputId": "fd80ef5d-6bb1-4a8e-a441-015a292019db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 125 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\\Done.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN =  max([len(sen) for sen in input_ids])+1\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "print('\\Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "c8yqNmwcy6F3"
      },
      "outputs": [],
      "source": [
        "# создадим attantion маску для кажого предложения\n",
        "attention_masks = []\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - если  ID = 0 тогда не стоит обрабатывать данный токен в процессе обучения, поскольку это паддинг\n",
        "    #   - если  ID > 0 тогда стоит использовать данный токен, поскольку он является частью предложения\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    attention_masks.append(att_mask)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "A_9KnA3JwsGh",
        "outputId": "30fa57b6-00b5-4bd0-e24d-a2bde1fcae71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PolyCollection at 0x7f38ca449ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.pcolor(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBKEaeDQMSRY",
        "outputId": "97a89460-2165-4656-9c23-0f4efe7f21ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,df.label.values, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, df.label.values,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "### даталоадер для вычисления полного градиента\n",
        "batch_size = 250#train_inputs.shape[0]\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader_for_full_grad = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "### для обучения\n",
        "batch_size = 16#train_inputs.shape[0]\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76dqayMsMXjw",
        "outputId": "0b89d5b4-9741-4f6c-c444-4a1eaf0f5f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JuB4rK2Mbfs",
        "outputId": "99874fae-dfd6-452f-9619-9856ebd13a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-42a06c90195a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_inputs = torch.tensor(train_inputs)\n",
            "<ipython-input-38-42a06c90195a>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_inputs = torch.tensor(validation_inputs)\n",
            "<ipython-input-38-42a06c90195a>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels = torch.tensor(train_labels)\n",
            "<ipython-input-38-42a06c90195a>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_labels = torch.tensor(validation_labels)\n",
            "<ipython-input-38-42a06c90195a>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_masks = torch.tensor(train_masks)\n",
            "<ipython-input-38-42a06c90195a>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_masks = torch.tensor(validation_masks)\n"
          ]
        }
      ],
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DR-Jsit6MgoL"
      },
      "outputs": [],
      "source": [
        "###full_grad_dataloader\n",
        "batch_size = 250#train_inputs.shape[0]\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader_for_full_grad = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "### for training\n",
        "batch_size = 16#train_inputs.shape[0]\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler,  batch_size=len(validation_data)//5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9thIb80MmyD",
        "outputId": "10504c65-a3a3-47c3-9781-8acd8288a295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# загрузим  DistilBertForSequenceClassification с одним выходным слоем и претрененными весами\n",
        "torch.manual_seed(15)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", \n",
        "    num_labels = 2, \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sRU2tnAyrdIO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(preds,labels):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7FGxaph1cdD"
      },
      "outputs": [],
      "source": [
        "optimizer =# исследуемый оптимизатор здесь\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9XJWQERM4Z3"
      },
      "outputs": [],
      "source": [
        "def training(model,n_epochs,optimizer):\n",
        "  for i in tqdm.tqdm(range(n_epochs)):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "      loss=get_loss(batch,model)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    validation(model)\n",
        "\n",
        "def get_metrics(model,batch):\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids,  \n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "  logits = torch.argmax(outputs.logits,1).detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "\n",
        "  return compute_metrics(logits, label_ids)\n",
        "           \n",
        "def validation(model):\n",
        "  print(\"Running Validation...\")\n",
        "  acc_set=[]\n",
        "  f1_set=[]\n",
        "  precision_set=[]\n",
        "  recall_set=[]\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    computed_results= get_metrics(model,batch)\n",
        "    acc_set.append(computed_results['accuracy'])\n",
        "    f1_set.append(computed_results['f1'])\n",
        "    precision_set.append(computed_results['precision'])\n",
        "    recall_set.append(computed_results['recall'])\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "\n",
        "  print(\"  Accuracy: {0:.2f}\".format(np.mean(acc_set)) )\n",
        "  print(\" f1=: {0:.2f}\".format(np.mean(f1_set)))\n",
        "  print(\" precision=: {0:.2f}\".format(np.mean(precision_set)))\n",
        "  print(\" recall=: {0:.2f}\".format(np.mean(recall_set)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9STw6ZVPcv9p"
      },
      "source": [
        "### Пункт №1(оптимизация языковой модели) \n",
        "Ваши эксперименты здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gko4t1E1c5Sa"
      },
      "source": [
        "Аналогичное задание для обработки изображений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtz8eENwc4lX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtOuyurFV0F4",
        "outputId": "2c0bf99f-553b-4ab2-d0a0-c777db6c1570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "BS=32\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfUkTYIJctdf"
      },
      "outputs": [],
      "source": [
        "model=torchvision.models.vgg32(pretrained=True)\n",
        "model.requires_grad_(False)\n",
        "\n",
        "model.classifier[6]=torch.nn.Linear(4096,10) #после небольшой адаптации весов последнего слоя все остальные веса предобученной модели имеет смысл разморозить\n",
        "device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model=model.to(device)\n",
        "optimizer=#оптимизатор здесь\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFr3EZ_SjUDi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njqfx2Y5jjoV"
      },
      "outputs": [],
      "source": [
        "def get_loss(batch,model):\n",
        "\n",
        "  inputs, labels = batch\n",
        "\n",
        "  outputs = model(inputs.to(device))\n",
        "  loss = criterion(outputs, labels.to(device))\n",
        "\n",
        "  return loss\n",
        "def get_accuracy(model,batch):\n",
        "  inputs, labels = batch\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs.to(device))\n",
        "  \n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "   \n",
        "\n",
        "  return flat_accuracy(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
        "def flat_accuracy(preds, labels):\n",
        "  # print(preds.shape())\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)                \n",
        "def validation(model):\n",
        "  print(\"Running Validation...\")\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    tmp_eval_accuracy = get_accuracy(model,batch)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "\n",
        "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CByWROx3y-8w"
      },
      "source": [
        "### Пункт №2 (оптимизация модели обработки изображений)\n",
        "Ваши эксперименты здесь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6NTwNtekBoY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d8e6b1cf32c42c09bcf29b88143ef8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efc1e4f258304c668f4ea2a3d40e2d32",
              "IPY_MODEL_436e9251ced54b8ea85246933354c49a",
              "IPY_MODEL_7560929a396d4568ad3037640ca812d4"
            ],
            "layout": "IPY_MODEL_bbd5c661289145eca1731ff77436527c"
          }
        },
        "efc1e4f258304c668f4ea2a3d40e2d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99b98af3639449588e40c9874e11a4f",
            "placeholder": "​",
            "style": "IPY_MODEL_f783b9b0daa84df080021235174acd61",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "436e9251ced54b8ea85246933354c49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f69e27d281246af8dad918c0629c638",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d98b18560c74a04a482bf7607922af7",
            "value": 440473133
          }
        },
        "7560929a396d4568ad3037640ca812d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfac346bea444f8690cb905619ba100d",
            "placeholder": "​",
            "style": "IPY_MODEL_0e9f091bea8f4b1895a2c69b937ad211",
            "value": " 440M/440M [00:01&lt;00:00, 384MB/s]"
          }
        },
        "bbd5c661289145eca1731ff77436527c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b99b98af3639449588e40c9874e11a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f783b9b0daa84df080021235174acd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f69e27d281246af8dad918c0629c638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d98b18560c74a04a482bf7607922af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfac346bea444f8690cb905619ba100d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9f091bea8f4b1895a2c69b937ad211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01e628655d71447ab34e606b03f5b661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff63dff9bd16434eadd245b318ab9d10",
              "IPY_MODEL_365a9d8df56a49b38a0ec7293bd6862f",
              "IPY_MODEL_aa4fd036b7624f43a56c6eb2822a6c03"
            ],
            "layout": "IPY_MODEL_f12a061750c44b86a87c02f6e2fb540f"
          }
        },
        "ff63dff9bd16434eadd245b318ab9d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_893cf9cfe27e43c4aa0344559da80435",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2fb1f6fbd64146beadcec27ffd39a3",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "365a9d8df56a49b38a0ec7293bd6862f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edec69bef3a44858350b8ece02dd6cf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_578726e51a714144a112783dfed24469",
            "value": 231508
          }
        },
        "aa4fd036b7624f43a56c6eb2822a6c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888d729505e34c5aac61c82b095ed5fa",
            "placeholder": "​",
            "style": "IPY_MODEL_c57d2b0f5a2b47f786bfa11e5e2acdee",
            "value": " 232k/232k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "f12a061750c44b86a87c02f6e2fb540f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "893cf9cfe27e43c4aa0344559da80435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2fb1f6fbd64146beadcec27ffd39a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4edec69bef3a44858350b8ece02dd6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578726e51a714144a112783dfed24469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "888d729505e34c5aac61c82b095ed5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57d2b0f5a2b47f786bfa11e5e2acdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f312297f9de49b0a55f7634972d9b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a858a49c39a647bbb8684d477a5ecdf8",
              "IPY_MODEL_e0fc84235bbd4647aa0850e639320114",
              "IPY_MODEL_97c57d9f67794c5f992f5c7f6f16be68"
            ],
            "layout": "IPY_MODEL_a06adac1e6234033943f806d5e47da51"
          }
        },
        "a858a49c39a647bbb8684d477a5ecdf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916215d6b55b4d79b374cdbf194bc07c",
            "placeholder": "​",
            "style": "IPY_MODEL_edbecd9a1f314f6dab26e9279cd27f09",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "e0fc84235bbd4647aa0850e639320114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09f1e456db1044f48186276b8d8f9fbd",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe5aed206b12467daaac2b9c5c53aaa7",
            "value": 28
          }
        },
        "97c57d9f67794c5f992f5c7f6f16be68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89ad300e1f194253b30ba29f2b32b6bc",
            "placeholder": "​",
            "style": "IPY_MODEL_1d61aede530f45edb9d885ea9759e0c9",
            "value": " 28.0/28.0 [00:00&lt;00:00, 2.08kB/s]"
          }
        },
        "a06adac1e6234033943f806d5e47da51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916215d6b55b4d79b374cdbf194bc07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbecd9a1f314f6dab26e9279cd27f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09f1e456db1044f48186276b8d8f9fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe5aed206b12467daaac2b9c5c53aaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89ad300e1f194253b30ba29f2b32b6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d61aede530f45edb9d885ea9759e0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}